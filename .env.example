# URL вашего GPU-сервера с Ollama
OLLAMA_URL=http://<GPU_SERVER_IP>:11434

# Модель под 6–16 ГБ VRAM (подходит qwen2.5 7B int4)
OLLAMA_MODEL=qwen2.5:7b-instruct-q4_0

# Контекст (A2000 6 ГБ: 2048–3072; T4 16 ГБ: 4096–8192)
OLLAMA_NUM_CTX=2048
OLLAMA_TEMPERATURE=0.0

# где лежат YAML-правила
RULES_DIR=./rules

# оценка символов на токен (для усечения текста под контекст)
CHARS_PER_TOKEN=3.2
